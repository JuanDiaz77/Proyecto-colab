{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOh7JJTx9J0FHR5eooRucD7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanDiaz77/Proyecto-colab/blob/main/Proyecto_Capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QboKa65_QnKE"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install scikit-learn joblib pandas fastapi uvicorn[standard] nest-asyncio pyngrok streamlit great_expectations -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "output_dir = Path(\"/content/proyecto_capstone\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# simulacion de PQRS\n",
        "classes = [\"PQR\", \"felicitacion\", \"queja\", \"solicitud\", \"denuncia\"]\n",
        "templates = {\n",
        "    \"PQR\": [\"Quisiera informaci√≥n sobre el estado de mi tr√°mite {}\",\n",
        "            \"Solicito copia del documento {}\",\n",
        "            \"¬øCu√°l es el procedimiento para {}?\"],\n",
        "    \"felicitacion\": [\"Gracias por el excelente servicio en la oficina de {}\",\n",
        "                     \"Quiero felicitar al equipo de {} por su atenci√≥n\",\n",
        "                     \"Muy agradecido por la ayuda recibida en {}\"],\n",
        "    \"queja\": [\"Presento una queja por la demora en {}\",\n",
        "              \"Insatisfecho con el servicio recibido en {}\",\n",
        "              \"No recib√≠ respuesta sobre {}\"],\n",
        "    \"solicitud\": [\"Solicito la reparaci√≥n de la v√≠a en {}\",\n",
        "                  \"Pido apoyo para el servicio de {}\",\n",
        "                  \"Necesito agendar una cita para {}\"],\n",
        "    \"denuncia\": [\"Deseo denunciar un robo en {}\",\n",
        "                \"Reporto actividades sospechosas cerca de {}\",\n",
        "                \"Denuncio maltrato en {}\"]\n",
        "}\n",
        "places = [\"la alcald√≠a\", \"la oficina de tr√°nsito\", \"el centro de atenci√≥n\", \"la calle 45\", \"la sede principal\", \"la estaci√≥n\"]\n",
        "\n",
        "rows = []\n",
        "for i in range(600):\n",
        "    cls = random.choice(classes)\n",
        "    template = random.choice(templates[cls])\n",
        "    place = random.choice(places)\n",
        "    text = template.format(place)\n",
        "    if random.random() < 0.2:\n",
        "        text += \" por favor\"\n",
        "    if random.random() < 0.15:\n",
        "        text = text.replace(\"Solicito\", \"Quisiera solicitar\")\n",
        "    rows.append({\"texto\": text, \"tipo\": cls})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(output_dir / \"dataset_solicitudes.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "zqrEiMrVQx0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Este c√≥digo entrena un modelo de clasificaci√≥n de texto (NLP) usando un pipeline con TF-IDF y Regresi√≥n Log√≠stica, y luego guarda el modelo entrenado en un archivo (model_pipeline.joblib).\n",
        "\n",
        "# Importa las librerias necesarias\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "#Separacion de los datos\n",
        "X = df[\"texto\"].values\n",
        "y = df[\"tipo\"].values\n",
        "\n",
        "#separacion de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "#Definicon del Pipilen\n",
        "pipeline = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), min_df=2)),\n",
        "    (\"clf\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Guarda modelo en el workspace de Colab\n",
        "model_path = output_dir / \"model_pipeline.joblib\"\n",
        "joblib.dump(pipeline, model_path)\n"
      ],
      "metadata": {
        "id": "X5qYGa4nQ7Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eval√∫a el modelo entrenado y guarda los resultados de la evaluaci√≥n en archivos .csv.\n",
        "\n",
        "#Importa las metricas\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Genera las prediciones\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "#Define las clases\n",
        "classes = [\"PQR\",\"felicitacion\",\"queja\",\"solicitud\",\"denuncia\"]\n",
        "\n",
        "#Calcula la matriz de confusion: Determina cuantas veces el modelo se equivoco y acerto en cada clase.\n",
        "cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
        "\n",
        "#Calcula el reporte de clasificacion - se guarda como diccionario para facilitar la convercion a tabla\n",
        "report = classification_report(y_test, y_pred, target_names=classes, output_dict=True)\n",
        "\n",
        "#guarda el resultado\n",
        "pd.DataFrame(cm, index=classes, columns=classes).to_csv(output_dir / \"confusion_matrix.csv\", encoding=\"utf-8-sig\")\n",
        "pd.DataFrame(report).to_csv(output_dir / \"classification_report.csv\", encoding=\"utf-8-sig\")\n",
        "\n",
        "#Guarda las predicciones para retroalimentar el modelo\n",
        "preds_df = pd.DataFrame({\"texto\": X_test, \"true\": y_test, \"pred\": y_pred})\n",
        "preds_df.to_csv(output_dir / \"predicciones_test.csv\", index=False, encoding=\"utf-8-sig\")\n"
      ],
      "metadata": {
        "id": "gjsHzhYBQ_Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenamiento y guardado del Script\n",
        "\n",
        "#Importacion de librerias y funciones\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import joblib\n",
        "\n",
        "# ruta:Carga desde el disco el pipeline entrenado (TF-IDF + Regresi√≥n Log√≠stica)\n",
        "model = joblib.load(\"/content/proyecto_capstone/model_pipeline.joblib\")\n",
        "\n",
        "#Crea la aplicaci√≥n FastAPI y le asigna un t√≠tulo\n",
        "app = FastAPI(title=\"Clasificador de solicitudes ciudadanas\")\n",
        "\n",
        "# Define el formato del JSON que se debe enviar al endpoint /predict.\n",
        "class InputText(BaseModel):\n",
        "    texto: str\n",
        "\n",
        "#Define un endpoint tipo POST llamado /predict.\n",
        "@app.post(\"/predict\")\n",
        "# recibe un objeto del tipo InputText\n",
        "def predict(item: InputText):\n",
        "  #Extrae el texto enviado del modelo recibido.\n",
        "    texto = item.texto\n",
        "    #Llama al modelo para predecir la clase del texto y toma la predicion.\n",
        "    pred = model.predict([texto])[0]\n",
        "    #Toma la probabilidad mas alta\n",
        "    proba = float(model.predict_proba([texto]).max())\n",
        "    #Devuelve la respuesta en formato JSON\n",
        "    return {\"prediccion\": pred, \"probabilidad\": proba}\n",
        "\n",
        "#Define un enpoint de tipo GET\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "  #Funcion de retorno de estado\n",
        "    return {\"status\": \"ok\", \"mensaje\": \"API funcionando correctamente\"}\n"
      ],
      "metadata": {
        "id": "RD-S0l41YW9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Libreria para exponer la API mediante URL publica\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "import threading\n",
        "import time\n",
        "import os\n",
        "\n",
        "#Habilita la reutilizaci√≥n del mismo bucle asincr√≥nico, necesario para que FastAPI funcione correctamente dentro de Google Colab.\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# rectifica la carpeta del proyecto para uvicorn\n",
        "os.chdir(\"/content/proyecto_capstone\")\n",
        "\n",
        "#Define el host y el puerto para ejecutar la API\n",
        "def run_uvicorn():\n",
        "    uvicorn.run(\"app:app\", host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "#hilo de ejecuci√≥n paralelo que correr√° Uvicorn.\n",
        "thread = threading.Thread(target=run_uvicorn, daemon=True)\n",
        "#Inicia el servidor de FASTAPI\n",
        "thread.start()\n",
        "time.sleep(2)\n",
        "\n",
        "#Crea el tunel publico y URL\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "print(\" API en ejecuci√≥n en:\", public_url)\n"
      ],
      "metadata": {
        "id": "NiFZ5uQnbQ89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Desactiva el puerto\n",
        "!fuser -k 8000/tcp\n"
      ],
      "metadata": {
        "id": "DPRadby_sdLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Token de logueo ngrok\n",
        "!ngrok authtoken 34nWVluqfWCUt0chClyAvO3RNMc_6DtsZ1KjCxj3YhTCeLGiV\n"
      ],
      "metadata": {
        "id": "z4PIn3qpb_ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cambia el directorio de la carpeta\n",
        "import os\n",
        "os.chdir(\"/content/proyecto_capstone\")\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "-eRYki1tcX82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#guarda el contenido del bloque para la compatibilidad en colab\n",
        "%%writefile app.py\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import joblib\n",
        "\n",
        "app = FastAPI(title=\"Clasificador de solicitudes ciudadanas\")\n",
        "\n",
        "# Cargar el modelo de machine learning\n",
        "model = joblib.load(\"model_pipeline.joblib\")\n",
        "\n",
        "class InputText(BaseModel):\n",
        "    texto: str\n",
        "\n",
        "#Crea la ruta POST para recibir el texto y clasificar\n",
        "@app.post(\"/predict\")\n",
        "def predict(item: InputText):\n",
        "    texto = item.texto\n",
        "    pred = model.predict([texto])[0]\n",
        "    proba = float(model.predict_proba([texto]).max())\n",
        "    return {\"prediccion\": pred, \"probabilidad\": proba}\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"status\": \"ok\", \"mensaje\": \"API funcionando correctamente\"}\n"
      ],
      "metadata": {
        "id": "e3N3PCdpdAw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/proyecto_capstone/validate.py\n",
        "import pandas as pd\n",
        "import great_expectations as gx\n",
        "\n",
        "# Cargar dataset\n",
        "df = pd.read_csv(\"/content/proyecto_capstone/dataset_solicitudes.csv\")\n",
        "\n",
        "print(\" Iniciando validaci√≥n de calidad de datos...\\n\")\n",
        "\n",
        "# Expectativas b√°sicas\n",
        "expectations = {\n",
        "    \"no valores nulos en texto\": df[\"texto\"].notnull().all(),\n",
        "    \"no valores nulos en tipo\": df[\"tipo\"].notnull().all(),\n",
        "    \"longitud m√≠nima del texto > 5\": (df[\"texto\"].str.len() > 5).all(),\n",
        "    \"clases v√°lidas\": set(df[\"tipo\"].unique()).issubset({\"PQR\",\"felicitacion\",\"queja\",\"solicitud\",\"denuncia\"})\n",
        "}\n",
        "\n",
        "for check, result in expectations.items():\n",
        "    print(f\"- {check}: {' OK' if result else ' Falla'}\")\n",
        "\n",
        "# Guardar resumen como CSV\n",
        "summary = pd.DataFrame(list(expectations.items()), columns=[\"check\", \"status\"])\n",
        "summary.to_csv(\"/content/proyecto_capstone/validacion_resumen.csv\", index=False)\n",
        "\n",
        "print(\"\\nüìÑ Resultados guardados en validacion_resumen.csv\")\n",
        "print(\" Validaci√≥n terminada.\")\n"
      ],
      "metadata": {
        "id": "rajZVbeckai5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instala la libreria para validar la calidad de los datos y la instala en colab\n",
        "!pip install great_expectations\n",
        "!python validate.py\n",
        "\n"
      ],
      "metadata": {
        "id": "lytmRhxegYFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python validate.py\n"
      ],
      "metadata": {
        "id": "uxs9EZuYi2Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"\"\"# Informe Breve del Proyecto Capstone\n",
        "\n",
        "## D√≠a 1: Entrenamiento del modelo\n",
        "Se cre√≥ un dataset de solicitudes ciudadanas simuladas (600 filas).\n",
        "Se entren√≥ un clasificador con TF-IDF + LogisticRegression y se evalu√≥ con matriz de confusi√≥n y reporte de clasificaci√≥n.\n",
        "\n",
        "## D√≠a 2: Despliegue simulado\n",
        "Se desarroll√≥ una API con FastAPI para clasificar texto en categor√≠as de tipo de solicitud.\n",
        "Se empaquet√≥ el servicio con Dockerfile, y se document√≥ la configuraci√≥n para despliegue simulado en Google Cloud Run.\n",
        "\n",
        "## D√≠a 3: Validaci√≥n y visualizaci√≥n\n",
        "Se valid√≥ el dataset con Great Expectations (sin nulos, columnas correctas, clases v√°lidas).\n",
        "Los resultados fueron 100 % exitosos.\n",
        "Se generaron archivos de log y CSV con los resultados.\n",
        "\n",
        "---\n",
        "Autor: Juan Pablo Mora Diaz\n",
        "Fecha: 30/10/2025\n",
        "\"\"\"\n",
        "from pathlib import Path\n",
        "Path(\"/content/proyecto_capstone/informe_breve.md\").write_text(texto, encoding=\"utf-8\")\n",
        "print(\"Informe creado \")\n"
      ],
      "metadata": {
        "id": "HtM39nvpqmLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, textwrap, subprocess, sys\n",
        "from pathlib import Path\n",
        "\n",
        "proj = Path(\"/content/proyecto_capstone\")\n",
        "if not proj.exists():\n",
        "    raise SystemExit(f\"No encontr√© la carpeta {proj}. Aseg√∫rate de que los archivos est√©n aqu√≠.\")\n",
        "\n",
        "md_file = proj / \"informe_breve.md\"\n",
        "pdf_file = proj / \"informe_breve.pdf\"\n",
        "if md_file.exists():\n",
        "    try:\n",
        "        try:\n",
        "            import reportlab\n",
        "        except Exception:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"reportlab\"], stdout=subprocess.DEVNULL)\n",
        "        from reportlab.lib.pagesizes import letter\n",
        "        from reportlab.pdfgen import canvas\n",
        "        text = md_file.read_text(encoding=\"utf-8\")\n",
        "        c = canvas.Canvas(str(pdf_file), pagesize=letter)\n",
        "        width, height = letter\n",
        "        margin = 40\n",
        "        y = height - margin\n",
        "        for paragraph in text.split(\"\\n\\n\"):\n",
        "            for line in textwrap.wrap(paragraph, width=95):\n",
        "                if y < margin + 20:\n",
        "                    c.showPage()\n",
        "                    y = height - margin\n",
        "                c.drawString(margin, y, line)\n",
        "                y -= 12\n",
        "            y -= 8\n",
        "        c.save()\n",
        "        print(\"PDF generado:\", pdf_file)\n",
        "    except Exception as e:\n",
        "        print(\"No se pudo generar PDF autom√°ticamente:\", e)\n",
        "else:\n",
        "    print(\"No se encontr√≥ informe_breve.md ‚Äî saltando generaci√≥n de PDF.\")\n",
        "\n",
        "files = [\n",
        "    \"dataset_solicitudes.csv\",\n",
        "    \"notebook_entrenamiento.ipynb\",\n",
        "    \"model_pipeline.joblib\",\n",
        "    \"confusion_matrix.csv\",\n",
        "    \"classification_report.csv\",\n",
        "    \"predicciones_test.csv\",\n",
        "    \"entrenamiento.log\",\n",
        "    \"app.py\",\n",
        "    \"Dockerfile\",\n",
        "    \"requirements.txt\",\n",
        "    \"streamlit_app.py\",\n",
        "    \"validate.py\",\n",
        "    \"validacion_resumen.csv\",\n",
        "    \"validacion_resultados.log\",\n",
        "    \"informe_breve.md\",\n",
        "    \"informe_breve.docx\",\n",
        "    \"informe_breve.pdf\"\n",
        "]\n",
        "\n",
        "files = [f for f in files if (proj / f).exists()]\n",
        "\n",
        "zip_path = Path(\"/content/Proyecto_Capstone_entregable.zip\")\n",
        "with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "    for fname in files:\n",
        "        zf.write(proj / fname, arcname=fname)\n",
        "\n",
        "print(\"ZIP creado en:\", zip_path)\n",
        "print(\"Archivos incluidos:\")\n",
        "for f in files:\n",
        "    print(\" -\", f)\n"
      ],
      "metadata": {
        "id": "MUfnY6i4oFcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/Proyecto_Capstone_entregable.zip\")\n"
      ],
      "metadata": {
        "id": "ES3ZdmESqCPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lista los archivos actuales\n",
        "!ls /content/proyecto_capstone\n"
      ],
      "metadata": {
        "id": "ibLNUV_2Z9ED"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}